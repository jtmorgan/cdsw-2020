{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracking traffic on the Burke Gilman trail\n",
    "This notebook will walk you through the process of exploring traffic patterns on the Burke Gilman trail, and asking and answering specific research questions using that data. The data we're using today comes from [data.seattle.gov](https://data.seattle.gov/) which is an online portal where the city of Seattle hosts publicly-available datasets. \n",
    "\n",
    "The exercises below will use the [Burke Gilman trail north of NE 70th St Bicycle and Pedestrian Counter](https://data.seattle.gov/Transportation/Burke-Gilman-Trail-north-of-NE-70th-St-Bicycle-and/2z5v-ecg8) dataset, which collects north and south traffic by bicyclists and pedestrians on a high-traffic portion of the Burke Gilman trail. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering the data\n",
    "Our first step here is to gather a sample of the data to work with. The full dataset is 53,000 rows, but we can use an API query to specify what time range we want to look at, so that we don't need to download the entire dataset. For now, we'll grab one year's worth of data—2019. \n",
    "\n",
    "If you want more practice with the Seattle Open Data API, you can use the notebook ``SODA_API_demo.ipynb``. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#download the requests library, a bundle of code that is useful for sending and retrieving data over the internet\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#the URL we're retrieving the data from. Copy/paste it into your browser to view it!\n",
    "api_endpoint = \"https://data.seattle.gov/resource/2z5v-ecg8.json?\"\n",
    "\n",
    "#the parameters we're passing to the API, to specify what subset of data we want.\n",
    "api_parameters = \"$limit=50000&$where=date > '2019-01-01T00:00:00' AND date < '2020-01-01T00:00:00'\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will combine these two strings into a single long URL, which is our API request. It ends up looking like this (run the cell below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(api_endpoint + api_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy and paste that full string into your browser to get a sneak peak at the data we'll be working with!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#request the data from the API\n",
    "api_request = requests.get(api_endpoint + api_parameters)\n",
    "\n",
    "#turn this data into a list of dictionaries, so that we can work with it in Python\n",
    "raw_data = api_request.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the data, let's see what it looks like..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#how many rows are in our dataset?\n",
    "print(len(raw_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's kind of hard to read, isn't it? Fortunately, there's another useful Python library called \"pretty print\" (``pprint``), that we can use to make it easier to read this data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import the pretty print library\n",
    "from pprint import pprint "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You use ``pprint`` the same way you use ``print``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pprint(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our data sample and we know how the data is organized (a list of dictionaries, with one dictionary for each hour of traffic), we can start asking research questions about the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question #1: how many people used the Burke Gilman during commute hours in 2019?\n",
    "\n",
    "City planners often need to know the traffic volumes on particular roads and trails, so that they can prioritize maintenance and improvements. Anyone who's been on the Burke Gilman on a weekday at 5pm knows that it's a busy thoroughfare, but how busy is it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our first step, we need to decide what we mean by commute hours. Let's say between 6am and 9:59am is the \"morning\" communte, and 3pm-6:59pm is the \"evening commute\".\n",
    "\n",
    "We'll store these values in two lists, so that as we loop through each hour in the dataset later we can check whether the traffic during that hour falls within the morning or evening commute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "morning_commute_hours = ['06:00:00','07:00:00', '08:00:00', '09:00:00']\n",
    "evening_commute_hours = ['15:00:00','16:00:00', '17:00:00', '18:00:00']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need some place to store the morning/evening commute counts, as we loop through the dataset. We'll create a dictionary with keys for 'morning' and 'evening' for this purpose. The values for each of these will start at 0, and increase as we loop through the dataset and add the traffic we see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create an empty dictionary to hold our counts\n",
    "commuters = {'morning':0, 'evening':0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can loop through our ``raw data`` list and examine each dictionary in that list. If the time of day in that dictionary matches one of the times we've listed in our morning and evening commute hour lists we made above, then we take the value of ``bgt_north_of_ne_70th_total`` for that dictionary and add it to one of the totals in ``commuters``. If it doesn't match, we move on to the next one and do the same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for hour_count in raw_data:\n",
    "\n",
    "    traffic_hour = hour_count['date'][11:19] #get the timestamp\n",
    "    \n",
    "    if traffic_hour in morning_commute_hours: #if it's in the morning, add the count to our morning total\n",
    "        commuters['morning'] = commuters['morning'] + int(hour_count['bgt_north_of_ne_70th_total'])\n",
    "    \n",
    "    elif traffic_hour in evening_commute_hours: #if it's in the evening, add the count to our evening total\n",
    "        commuters['evening'] = commuters['evening'] + int(hour_count['bgt_north_of_ne_70th_total'])\n",
    "    \n",
    "    else:\n",
    "        pass #we don't care who's on the BGT during non-commute hours, so we ignore it and move on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the loop we just made"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### interlude 1: data types\n",
    "If you scroll up to our pprinted dataset above, you'll see that the numeric values for ``bgt_north_of_ne_70th_total`` (the hourly traffic counts) have '' around them. This means they are being stored as strings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#we can ask Python to tell us what type of value this is using 'type'\n",
    "print(type(raw_data[0]['bgt_north_of_ne_70th_total']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to add these numeric values together, we will need to turn them into integers. That's what's happening when you see ``int(hour_count['bgt_north_of_ne_70th_total'])`` in the loop above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#converting the string to an integer\n",
    "str_to_int = int(raw_data[0]['bgt_north_of_ne_70th_total'])\n",
    "\n",
    "print(type(str_to_int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### interlude 2: slicing\n",
    "The date and time for each item in the list is stored in a single string, like ``'2019-01-01T06:00:00.000'`` Right now, we are only interested in the time of day, which is in the middle—between \"T\" (position 10) and \".\" (position 19), so we slice the beginning and the end of the string off before we compare the value with our commute hour lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(raw_data[0]['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(raw_data[0]['date'][:11]) #slice the string to just get the stuff before the time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(raw_data[0]['date'][19:]) #slice the string to just get the stuff after the time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(raw_data[0]['date'][11:19]) #slice the string to just get the time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the answer to Q1\n",
    "Now if our loop above worked, we'll know how many people used the Burke Gilman during commute hours in 2019 (at 70th street, at least)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pprint(commuters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#we can make these values into a human readable sentence, if we convert the ints back into strings\n",
    "print(\"There were \" \n",
    "    + str(commuters['morning']) \n",
    "    + \" morning commuters and \" \n",
    "    + str(commuters['evening']) \n",
    "    + \" on the Burke Gilman at 70th Street in 2019!\"\n",
    "     )\n",
    "      \n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: what were the busiest hours on the Burke Gilman in 2019?\n",
    "Let's say you want to know when the Burke Gilman is least likely to be congested, so you can plan your trip. How would you find this out? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this, we need to start with a list of all of the hours of the day. We could do this manually by creating a list like we did with the morning and evening commute hours lists above, but since there are 24 hours in a day that would take a long time to type out manually! Is there a quicker way?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create an empty dictionary, that we will fill with hours\n",
    "traffic_by_hour = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loop through the dataset again...\n",
    "for hour_data in raw_data:\n",
    "    \n",
    "    traffic_hour = hour_data['date'][11:19] #grab the hour value from the item\n",
    "    \n",
    "    #if haven't seen this hour yet during the loop...\n",
    "    if traffic_hour not in traffic_by_hour.keys():\n",
    "        \n",
    "        # ...create an item for it in our dictionary that we can use later to track our cumulative hourly counts\n",
    "        traffic_by_hour[traffic_hour] = 0 #e.g {'01:00:00' : 0}\n",
    "   \n",
    "    else:\n",
    "        pass\n",
    "        #if we've already seen this hour and stored it in our dictionary, ignore it and move on to the next one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#how many hours in our list?\n",
    "len(traffic_by_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#what does our list look like?\n",
    "pprint(traffic_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the answer to Q2\n",
    "Awesome! Now that we have buckets ready to hold counts for each hour in the day, we can loop through the raw data again and start calculating the traffic counts for each hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for hour_data in raw_data:\n",
    "    \n",
    "    traffic_hour = hour_data['date'][11:19]\n",
    "\n",
    "    traffic_by_hour[traffic_hour] =  traffic_by_hour[traffic_hour] + int(hour_data['bgt_north_of_ne_70th_total'])\n",
    "\n",
    "    #you can also un-comment the following line and run it instead of the line directly above.\n",
    "    #this is a slightly shorter way to do the same thing. Re-set traffic_by_hour to zero and try it!\n",
    "#     traffic_by_hour[traffic_hour] += int(hour_data['bgt_north_of_ne_70th_total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pprint(traffic_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the busiest hour is between 5 and 6pm!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### interlude 3: plus-equals\n",
    "Writing long lines of code like ``commuters['morning'] = commuters['morning'] + int(hour_count['bgt_north_of_ne_70th_total'])`` can be tedious, and it makes it more likely that you will make a typo that causes your code to crash. There's an easier way!\n",
    "\n",
    "Instead of writing ``thing_one = thing_one + thing_two``, you can write ``thing_one += thing_two``. It does the same thing! \n",
    "\n",
    "You can try this out yourself by re-running cells 35-38 above, and then using the code ``traffic_by_hour[traffic_hour] += int(hour_data['bgt_north_of_ne_70th_total'])`` \n",
    "\n",
    "...instead of the line ``traffic_by_hour[traffic_hour] =  traffic_by_hour[traffic_hour] + int(hour_data['bgt_north_of_ne_70th_total'])``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Going further with Question 3\n",
    "- Challenge #1: How would you use Python to find the HOUR with the most traffic? This list is short, so we can probably easily identify the element with the most traffic just by looking at it. But what if it had 10k items in it? How would YOU find the hour with the most traffic?\n",
    "- Challegen #2: How would you find the busiest DAY on the Burke Gilman in 2019? You should be able to answer this question with the same techniques you used to find the busiest hour!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: What is the busiest hours for bikes vs pedestrians?\n",
    "One cool thing about this dataset is that it doesn't just count by hour, it counts by what kind of traffic: bikes or pedestrians. Let's run the same set of commands as above, but this time we'll break things apart into bikes and peds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create an empty dictionary\n",
    "traffic_by_hour_bp = {}\n",
    "\n",
    "for hour_data in raw_data:\n",
    "    \n",
    "    traffic_hour = hour_data['date'][11:19]\n",
    "    \n",
    "    #if haven't seen this hour yet, create an item for it that we can use to track hourly counts later\n",
    "    if traffic_hour not in traffic_by_hour_bp.keys():\n",
    "        \n",
    "        #this time, we create a dictionary-in-a-dictionary, to hold our bike and pedestrian counts separately\n",
    "        traffic_by_hour_bp[traffic_hour] = {'bikes' : 0, 'pedestrians' : 0}\n",
    "    \n",
    "    else:\n",
    "        pass\n",
    "        #if we've already seen this hour and stored it in our dictionary, ignore it and move on\n",
    "\n",
    "pprint(traffic_by_hour_bp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the answer to Q3\n",
    "Now that we have the right buckets for every value we want to capture, we're ready to get counts for bikes and peds separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for hour_data in raw_data:\n",
    "    \n",
    "    traffic_hour = hour_data['date'][11:19]\n",
    "    \n",
    "    #note that we're using the 'plus-equals' technique now, which means we have to write less code\n",
    "    traffic_by_hour_bp[traffic_hour]['bikes'] += int(hour_data['bike_north']) #add northbound bike counts\n",
    "    traffic_by_hour_bp[traffic_hour]['bikes'] += int(hour_data['bike_south']) #add southbound bike counts\n",
    "    \n",
    "    traffic_by_hour_bp[traffic_hour]['pedestrians'] += int(hour_data['ped_north']) #add northbound ped counts\n",
    "    traffic_by_hour_bp[traffic_hour]['pedestrians'] += int(hour_data['ped_south']) #add sounthbound ped counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pprint(traffic_by_hour_bp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that there is more data in the notebook, it's a bit harder to figure out the busiest hour for bikes and pedestrians separately, just by looking. So let's use a quick loop to find this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_bike = ['some hour', 0]\n",
    "top_ped = ['some hour', 0]\n",
    "\n",
    "for hour, traffic in traffic_by_hour_bp.items():\n",
    "\n",
    "    if traffic['bikes'] > top_bike[1]:\n",
    "        top_bike[0] = hour\n",
    "        top_bike[1] = traffic['bikes']\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    if traffic['pedestrians'] > top_ped[1]:\n",
    "        top_ped[0] = hour\n",
    "        top_ped[1] = traffic['pedestrians']\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "print(\"The hour with the most bike traffic is \" + top_bike[0] + \", with \" + str(top_bike[1]) + \" bikes!\")\n",
    "print(\"The hour with the most pedestrian traffic is \" + top_ped[0] + \", with \" + str(top_ped[1]) + \" pedestrians!\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Going further with Question 3\n",
    "- Challenge #3: Were there more bikes or pedestrians using the Burke Gilman trail in 2019?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4: What is the busiest hour for bikes vs. peds AND northbound vs. southbound?\n",
    "\n",
    "If we want, we can break our data down by bikes vs. peds AND northbound vs. southbound. This is useful because it helps us understand how many people are using the Burke Gilman trail for daily commuting, not just for pleasure trips. \n",
    "\n",
    "Splitting bike and pedestrian traffic by northboud/southbound is actually almost as easy as lumping them together. We just make our dictionary-in-a-dictionary a little more complex.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a new empty dictionary\n",
    "traffic_by_hour_bpd = {}\n",
    "\n",
    "for hour_data in raw_data:\n",
    "    \n",
    "    traffic_hour = hour_data['date'][11:19]\n",
    "    \n",
    "    if traffic_hour not in traffic_by_hour_bpd.keys():\n",
    "\n",
    "        traffic_by_hour_bpd[traffic_hour] = {'bikes north' : 0, 'pedestrians north' : 0, \n",
    "                                            'bikes south' : 0, 'pedestrians south' : 0}  \n",
    "    else:\n",
    "        pass\n",
    "\n",
    "pprint(traffic_by_hour_bpd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now instead of adding bike_north + bike_south etc together, we store each of those counts in their own key/value bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for hour_data in raw_data:\n",
    "    \n",
    "    traffic_hour = hour_data['date'][11:19]\n",
    "    \n",
    "    traffic_by_hour_bpd[traffic_hour]['bikes north'] += int(hour_data['bike_north']) #store count in bike_north\n",
    "    traffic_by_hour_bpd[traffic_hour]['bikes south'] += int(hour_data['bike_south']) #store count in bike_south\n",
    "    \n",
    "    traffic_by_hour_bpd[traffic_hour]['pedestrians north'] += int(hour_data['ped_north'])\n",
    "    traffic_by_hour_bpd[traffic_hour]['pedestrians south'] += int(hour_data['ped_south'])\n",
    "\n",
    "pprint(traffic_by_hour_bpd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answering question 4\n",
    "I will leave it up to you to find the answer to any of these questions (you already know how to do it!)\n",
    "- What is the busiest hour for northbound bike traffic? For southbound bike traffic?\n",
    "- What is the busiest hour for northbound pedestrian traffic? For southbound pedestrian traffic?\n",
    "\n",
    "If you don't feel like writing code to answer these questions right now, that's okay. Below, I will show you how to export this data in a format that can be used to easily create timeseries graphs in a spreadsheet. It will be much easier to answer these questions with a graph than by looking at rows of numbers!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting the bike/ped north/south dataset for visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have some nice rich data that we can graph in a spreadsheet program like Google Sheets or Microsoft Excel. \n",
    "\n",
    "But to do that, we will need to convert the data to CSV format and export it into a file. We ideally want a format that has a row for each hour, and columns like\n",
    "``hour_of_day | bikes_north | bikes_south | pedestrians_north | pedestrians_south``\n",
    " \n",
    "The best way to do this is to convert our data from a nested dictionary to a nested list (a list-of-lists!), where each sub-list (which will be a row in our CSV file), contains the values in a consistent order, like:\n",
    "\n",
    "``[hour_of_day, bike_north, bike_south, ped_north, ped_south]``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a new empty 'master list'\n",
    "traffic_by_hour_mode_direction = []\n",
    "\n",
    "#for each hour in our traffic-by-hour-mode-direction dictionary...\n",
    "for hour, counts in traffic_by_hour_bpd.items():\n",
    "    \n",
    "    #...create a new sub-list that will store the hour, bike, and pedestrian data in a consistent order\n",
    "    list_element = [] #new empty sub-list\n",
    "    list_element.append(hour) #add the hour in, e.g. ['06:00:00']\n",
    "    list_element.append(counts['bikes north']) #append bike north count, e.g. ['06:00:00', 484]\n",
    "    list_element.append(counts['bikes south']) #append bike south count, e.g. ['06:00:00', 484, 82]\n",
    "    list_element.append(counts['pedestrians north']) # etc...\n",
    "    list_element.append(counts['pedestrians south']) # etc... \n",
    "    \n",
    "    traffic_by_hour_mode_direction.append(list_element) #add this list to the end of our growing master list\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pprint(traffic_by_hour_mode_direction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This worked! BUT something odd happened. Can you see it? For some reason, our '00:00:00' hour got moved to the end of the list. \n",
    "\n",
    "This happened because Python dictionaries do not reliably preserve the order of items! So even though the data looked like it was in the right order when we had it in the dictionary, when we created our new master list from ``traffic_by_hour_bpd`` it ended up a little out of order. \n",
    "\n",
    "Fortunately, unlike dictionaries, lists-of-lists are easy to sort! Especially if you want to sort by the first item in each sub-list, which we do!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sort the list in 'alphabetical order' by the first sub-item, which is the hour stamp\n",
    "traffic_by_hour_mode_direction.sort() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pprint(traffic_by_hour_mode_direction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our data in a list, it's easy to export to a CSV file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bg_traffic_bike_ped_2019.csv', 'w', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    #write a header row\n",
    "    writer.writerow(('hour of the day', \n",
    "                     'northbound bikes', \n",
    "                     'southbound bikes', \n",
    "                     'northbound pedestrians',\n",
    "                     'southbound pedestrians'))\n",
    "    \n",
    "    for i in traffic_by_hour_mode_direction:\n",
    "        writer.writerow((i[0], i[1], i[2], i[3], i[4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5 (Grand challenge!): What day of the week is busiest on the Burke Gilman?\n",
    "\n",
    "If we really want to understand whether people use the Burke Gilman for commuting, rather than just for recreation, we probably need to know what days of the week are busiest. \n",
    "\n",
    "We can answer this question using the same basic approach we used to answer the previous questions, but we will need a little bit of help. Since days of the week occur on different calendar days every year, we need a way to find out, for any given date in 2019, what day of the week that date fell on.\n",
    "\n",
    "Python has a couple of tools that can help us with this:\n",
    "- ``parse`` is a function from the ``dateutil`` library that can turn a date that is formatted as a string into a \"datetime object\", which is a format that Python understands as a real date, not just a series of characters.\n",
    "- ``weekday`` is a function from the ``datetime`` library that can tell you, for any valid datetime object, what day of the week that date fell on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime #yes, I know this seems redundant\n",
    "from dateutil import parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try out formatting one of our strings as a datetime object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#here's a random date from our dataset, in its native string format\n",
    "print(raw_data[234]['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now let's use the parse function to turn that into datetime format, which Python can work with\n",
    "parser.parse(raw_data[234]['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That worked! We can save this datetime object in its own variable. That will let us do things with it (like find out what day of the week January 10th, 2019 was)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_date = parser.parse(raw_data[234]['date'])\n",
    "print(my_date)\n",
    "print(type(my_date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know how to parse strings into datetime objects, we can use the ``datetime.weekday()`` function to find out what day of the week it was. This function will return a value between 0 (Monday) and 6 (Sunday) for any valid date you give it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_date.weekday() #starts at 0!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like January 10th was a Thursday (you can check your calendar to confirm this)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answering Question 5\n",
    "Now that you know how to find out the day of the week for any date in our ``raw_data`` dataset, you should be able to find out which weekday or weekend day sees the most traffic on the Burke Gilman. You'll be able to use loops, \"if\" statements, and dictionaries to calculate the totals for each day. \n",
    "\n",
    "Before you start, think for a minute: what do you think the answer will be, based on your own experience or your prior knowledge? Do you think the Burke Gilman is used more on weekdays or weekends? Why? Are some weekdays busier than others? Why?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations! \n",
    "\n",
    "You have now mastered manipulating timeseries data in Python. There are plenty of other techniques, tools, and time-saving tricks that you can learn to build on these skills, but many data scientists who use Python every day do this kind of work using the same basic approach you just learned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenges: going further\n",
    "\n",
    "Here are some additional questions that you now have the tools you need to answer, based on what you've done today:\n",
    "\n",
    "- what day of the week is busiest for bikes? Is it the same as the busiest day for pedestrians?\n",
    "- what month of the year is busiest? (aka do Seattlites really like to ride in the rain?)\n",
    "- has the Burke Gilman gotten busier over time? (the dataset we have goes back to 2014!)\n",
    "- do fewer people commute on the Burke Gilman when it's cold out? (hint: try combining this dataset with the [dataset on road temperature over time](https://data.seattle.gov/Public-Safety/Road-Weather-Information-Stations/egc4-d24i/data)\n",
    "- do more people commute into Seattle in the mornings by bike on the Burke Gilman, or on the [the Mountain to Sound Trail](https://data.seattle.gov/Transportation/MTS-Trail-west-of-I-90-Bridge-Bicycle-and-Pedestri/u38e-ybnc)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other data.seattle.gov datasets that you can do timeseries with...\n",
    "- Fremont bridge bicycle counter: https://data.seattle.gov/Transportation/Fremont-Bridge-Bicycle-Counter/65db-xm6k\n",
    "- Spokane Street bridge bicycle counter: https://data.seattle.gov/Transportation/Spokane-St-Bridge-Bicycle-Counter/upms-nr8w\n",
    "- Mountain to Sound trail bicycle + pedestrian counter: https://data.seattle.gov/Transportation/MTS-Trail-west-of-I-90-Bridge-Bicycle-and-Pedestri/u38e-ybnc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More complex datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://data.seattle.gov/Public-Safety/Terry-Stops/28ny-9ts8\n",
    "- https://data.seattle.gov/Permitting/Building-Permits/76t5-zqzr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
